{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27172f75",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Demo for PathRWKV</h1> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Python](https://img.shields.io/badge/Python-3.12.12-3776AB?style=for-the-badge&logo=python&logoColor=white)\n",
    "![PyTorch](https://img.shields.io/badge/PyTorch-2.9.1-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)\n",
    "![CUDA](https://img.shields.io/badge/CUDA-12.8-76B900?style=for-the-badge&logo=nvidia&logoColor=white)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "## üìö Summary\n",
    "\n",
    "This notebook demonstrated the complete PathRWKV pipeline:\n",
    "\n",
    "| Step | Description | Output |\n",
    "|------|-------------|--------|\n",
    "| 1Ô∏è‚É£ Preprocessing | WSI ‚Üí Tiles | `.jpeg` images + `dataset.csv` |\n",
    "| 2Ô∏è‚É£ Embedding | Tiles ‚Üí Features | `.safetensors` files |\n",
    "| 3Ô∏è‚É£ Training | Features ‚Üí Model | Checkpoints + TensorBoard logs |\n",
    "| 4Ô∏è‚É£ Testing | Model ‚Üí Metrics | `results.json` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c02a6d3",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Google Colab Setup\n",
    "\n",
    "Run this cell only if you are using Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üåê Running in Google Colab!\")\n",
    "    \n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/Puzzle-Logic/PathRWKV.git\n",
    "    %cd PathRWKV\n",
    "    \n",
    "    # Install system dependencies\n",
    "    !apt-get update && apt-get install -y openslide-tools\n",
    "    \n",
    "    # Install Python dependencies\n",
    "    !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n",
    "    !pip install pytorch-lightning torchmetrics timm monai polars pyyaml safetensors\n",
    "    !pip install scikit-survival openslide-python pillow tqdm scipy tensorboard matplotlib\n",
    "    \n",
    "    # Mount Google Drive (optional, for data storage)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    print(\"‚úÖ Colab setup complete!\")\n",
    "else:\n",
    "    print(\"üíª Running locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c708b",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017611c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the project root\n",
    "if IN_COLAB:\n",
    "    PROJECT_ROOT = Path('/content/PathRWKV')\n",
    "else:\n",
    "    PROJECT_ROOT = Path('.').resolve()\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Print system info\n",
    "print(f\"üêç Python: {sys.version}\")\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05500df9",
   "metadata": {},
   "source": [
    "---\n",
    "## üóÇÔ∏è Step 1: WSI Preprocessing (Tiling)\n",
    "\n",
    "This step converts Whole Slide Images (WSI) into small tiles for feature extraction.\n",
    "\n",
    "### Key Parameters:\n",
    "- `tile_size`: Size of each tile (default: 224√ó224 pixels)\n",
    "- `target_mpp`: Microns per pixel (default: 0.5 for 20x magnification)\n",
    "- `t_occupancy`: Minimum tissue occupancy threshold (default: 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bb570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for preprocessing\n",
    "PREPROCESS_CONFIG = {\n",
    "    'input_dir': '/path/to/your/wsi/folder',  # üìÇ Change this to your WSI directory\n",
    "    'output_dir': '/path/to/output/tiles',     # üìÇ Change this to output directory\n",
    "    'tile_size': 224,\n",
    "    'target_mpp': 0.5,\n",
    "    't_occupancy': 0.1,\n",
    "    'num_workers': 8,\n",
    "    'mode': None,  # Set to 'TCGA' for TCGA datasets\n",
    "}\n",
    "\n",
    "print(\"üìã Preprocessing Configuration:\")\n",
    "for key, value in PREPROCESS_CONFIG.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "# ‚ö†Ô∏è This may take a long time depending on the number of slides\n",
    "from UpStream.preprocess import process_all_slides\n",
    "\n",
    "process_all_slides(\n",
    "    input_dir=PREPROCESS_CONFIG['input_dir'],\n",
    "    output_dir=PREPROCESS_CONFIG['output_dir'],\n",
    "    tile_size=PREPROCESS_CONFIG['tile_size'],\n",
    "    target_mpp=PREPROCESS_CONFIG['target_mpp'],\n",
    "    t_occupancy=PREPROCESS_CONFIG['t_occupancy'],\n",
    "    num_workers=PREPROCESS_CONFIG['num_workers'],\n",
    "    mode=PREPROCESS_CONFIG['mode'],\n",
    "    gen_thumbnails=True,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Preprocessing step ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b15a935",
   "metadata": {},
   "source": [
    "### üìä Visualize Tiling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tiles(tiles_dir, slide_name, num_tiles=16):\n",
    "    \"\"\"\n",
    "    Visualize sample tiles from a preprocessed slide.\n",
    "    \n",
    "    Args:\n",
    "        tiles_dir: Directory containing tile images\n",
    "        slide_name: Name of the slide folder\n",
    "        num_tiles: Number of tiles to display\n",
    "    \"\"\"\n",
    "    slide_dir = Path(tiles_dir) / slide_name\n",
    "    \n",
    "    if not slide_dir.exists():\n",
    "        print(f\"‚ùå Slide directory not found: {slide_dir}\")\n",
    "        return\n",
    "    \n",
    "    tile_files = list(slide_dir.glob('*.jpeg'))[:num_tiles]\n",
    "    \n",
    "    if len(tile_files) == 0:\n",
    "        print(f\"‚ùå No tiles found in {slide_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_cols = 4\n",
    "    n_rows = (len(tile_files) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for idx, (ax, tile_path) in enumerate(zip(axes, tile_files)):\n",
    "        img = Image.open(tile_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(tile_path.stem[:15] + '...' if len(tile_path.stem) > 15 else tile_path.stem)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for ax in axes[len(tile_files):]:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sample Tiles from {slide_name}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_tiles('/path/to/output/tiles', 'slide_001')\n",
    "print(\"üìä Tile visualization function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735bae9",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Step 2: Feature Embedding\n",
    "\n",
    "Extract features from tiles using **Prov-GigaPath**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for embedding\n",
    "EMBED_CONFIG = {\n",
    "    'input_dir': '/path/to/tiles/folder',      # üìÇ Directory containing tile folders\n",
    "    'output_dir': '/path/to/embeddings',       # üìÇ Output directory for .safetensors files\n",
    "    'model_name': 'hf_hub:prov-gigapath/prov-gigapath',  # Foundation model\n",
    "    'batch_size': 512,\n",
    "    'num_workers': 8,\n",
    "    'devices': -1,  # -1 for all available GPUs\n",
    "    'compile_model': True,  # Use torch.compile for speedup\n",
    "}\n",
    "\n",
    "print(\"üß† Embedding Configuration:\")\n",
    "for key, value in EMBED_CONFIG.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HuggingFace token for Prov-GigaPath (requires access)\n",
    "os.environ['HF_TOKEN'] = 'your_huggingface_token_here'  # üîë Replace with your token\n",
    "\n",
    "# Run embedding extraction\n",
    "# ‚ö†Ô∏è This may take a long time depending on the number of slides\n",
    "from UpStream.embed import main as embed_main\n",
    "\n",
    "class EmbedArgs:\n",
    "    input_dir = EMBED_CONFIG['input_dir']\n",
    "    output_dir = EMBED_CONFIG['output_dir']\n",
    "    model_name = EMBED_CONFIG['model_name']\n",
    "    batch_size = EMBED_CONFIG['batch_size']\n",
    "    num_workers = EMBED_CONFIG['num_workers']\n",
    "    devices = EMBED_CONFIG['devices']\n",
    "    compile_model = EMBED_CONFIG['compile_model']\n",
    "    pretrained = True\n",
    "\n",
    "embed_main(EmbedArgs())\n",
    "\n",
    "print(\"‚úÖ Embedding step ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad1856",
   "metadata": {},
   "source": [
    "### üìä Inspect Embedding Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import safe_open\n",
    "\n",
    "def inspect_embeddings(safetensor_path):\n",
    "    \"\"\"\n",
    "    Inspect a safetensor file containing slide embeddings.\n",
    "    \n",
    "    Args:\n",
    "        safetensor_path: Path to .safetensors file\n",
    "    \"\"\"\n",
    "    path = Path(safetensor_path)\n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå File not found: {path}\")\n",
    "        return\n",
    "    \n",
    "    with safe_open(path, framework='pt', device='cpu') as f:\n",
    "        features = f.get_tensor('features')\n",
    "        coords = f.get_tensor('coords_yx')\n",
    "    \n",
    "    print(f\"üìÅ File: {path.name}\")\n",
    "    print(f\"  ‚Ä¢ Number of tiles: {features.shape[0]}\")\n",
    "    print(f\"  ‚Ä¢ Feature dimension: {features.shape[1]}\")\n",
    "    print(f\"  ‚Ä¢ Coordinates shape: {coords.shape}\")\n",
    "    print(f\"  ‚Ä¢ Feature stats: mean={features.mean():.4f}, std={features.std():.4f}\")\n",
    "    \n",
    "    # Visualize coordinate distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    axes[0].scatter(coords[:, 1], coords[:, 0], alpha=0.5, s=5)\n",
    "    axes[0].set_xlabel('X coordinate')\n",
    "    axes[0].set_ylabel('Y coordinate')\n",
    "    axes[0].set_title('Tile Positions')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    axes[1].hist(features.mean(dim=1).numpy(), bins=50, edgecolor='black')\n",
    "    axes[1].set_xlabel('Mean Feature Value')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Feature Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "inspect_embeddings('/path/to/embeddings/slide_001.safetensors')\n",
    "print(\"üìä Embedding inspection function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540aa261",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ Step 3: Training PathRWKV\n",
    "\n",
    "Train **PathRWKV** for multiple instance learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ed294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "TRAIN_CONFIG = {\n",
    "    # Environment\n",
    "    'seed': 42,\n",
    "    'devices': '0',  # GPU ID(s), e.g., '0', '0%1' for multi-GPU\n",
    "    \n",
    "    # Data\n",
    "    'data_path': '/path/to/dataset',  # üìÇ Root path containing embeddings\n",
    "    'dataset_name': 'CAMELYON16',     # Dataset name (must match config folder)\n",
    "    'max_tiles': 2000,                # Maximum tiles per slide during training\n",
    "    'num_workers': 8,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 4,\n",
    "    'epochs': 100,\n",
    "    'lr': 1e-4,\n",
    "    'lrf': 0.1,\n",
    "    'early_stop_epoch': 10,\n",
    "    \n",
    "    # Paths\n",
    "    'runs_path': str(PROJECT_ROOT / 'runs'),\n",
    "}\n",
    "\n",
    "print(\"üöÄ Training Configuration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a44858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training arguments\n",
    "class TrainArgs:\n",
    "    def __init__(self, config):\n",
    "        for key, value in config.items():\n",
    "            setattr(self, key, value)\n",
    "        self.mode = 'train'\n",
    "        self.tasks = None  # Use all tasks from config\n",
    "        self.resume_ckpt = None\n",
    "        self.test_ckpt = None\n",
    "        self.val_interval = 1.0\n",
    "        self.disable_pbar = False\n",
    "\n",
    "args = TrainArgs(TRAIN_CONFIG)\n",
    "\n",
    "print(\"üìã Training arguments prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training (uncomment to execute)\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from DownStream.utils.pipeline import WSIPipeline\n",
    "from DownStream.utils.dataset import data_module\n",
    "from DownStream.utils.utils import initialize_experiment\n",
    "\n",
    "seed_everything(args.seed, workers=True)\n",
    "\n",
    "# Initialize experiment\n",
    "(\n",
    "    args.data_path,\n",
    "    args.input_dim,\n",
    "    args.tasks,\n",
    "    args.runs_path,\n",
    "    args.runs_name,\n",
    "    args.devices,\n",
    ") = initialize_experiment(args)\n",
    "\n",
    "# Setup logger and callbacks\n",
    "tb_logger = TensorBoardLogger(\n",
    "    version='tb',\n",
    "    name=args.runs_name,\n",
    "    default_hp_metric=False,\n",
    "    save_dir=str(args.runs_path.parent),\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=args.runs_path / 'checkpoints',\n",
    "    filename='best',\n",
    "    monitor='Val/Loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='Val/Loss',\n",
    "    min_delta=0.00001,\n",
    "    patience=args.early_stop_epoch,\n",
    "    verbose=True,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    logger=tb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    devices=args.devices,\n",
    "    precision='bf16-mixed',\n",
    "    max_epochs=args.epochs,\n",
    "    num_sanity_val_steps=0,\n",
    "    enable_model_summary=True,\n",
    "    val_check_interval=args.val_interval,\n",
    "    strategy='ddp' if len(args.devices) != 1 else 'auto',\n",
    ")\n",
    "\n",
    "# Train!\n",
    "dm = data_module(args)\n",
    "model = WSIPipeline(args)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "print(\"‚úÖ Training step completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bebd4",
   "metadata": {},
   "source": [
    "### üìà Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Specify the logs directory\n",
    "%tensorboard --logdir /path/to/runs\n",
    "\n",
    "print(\"üìà TensorBoard ready (uncomment command to launch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1775b",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Step 4: Testing and Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49127d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Configuration\n",
    "TEST_CONFIG = {\n",
    "    **TRAIN_CONFIG,\n",
    "    'test_ckpt': None,  # Path to checkpoint, None uses best.ckpt from runs_path\n",
    "}\n",
    "\n",
    "print(\"üìä Testing Configuration:\")\n",
    "for key in ['data_path', 'dataset_name', 'test_ckpt']:\n",
    "    print(f\"  ‚Ä¢ {key}: {TEST_CONFIG[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run testing\n",
    "\n",
    "test_args = TrainArgs(TEST_CONFIG)\n",
    "test_args.mode = 'test'\n",
    "\n",
    "seed_everything(test_args.seed, workers=True)\n",
    "\n",
    "(\n",
    "    test_args.data_path,\n",
    "    test_args.input_dim,\n",
    "    test_args.tasks,\n",
    "    test_args.runs_path,\n",
    "    test_args.runs_name,\n",
    "    test_args.devices,\n",
    ") = initialize_experiment(test_args)\n",
    "\n",
    "# Setup trainer for testing\n",
    "test_trainer = Trainer(\n",
    "    logger=False,\n",
    "    callbacks=None,\n",
    "    devices=test_args.devices,\n",
    "    precision='bf16-mixed',\n",
    ")\n",
    "\n",
    "# Load model and test\n",
    "dm = data_module(test_args)\n",
    "ckpt_path = (\n",
    "    test_args.test_ckpt\n",
    "    if test_args.test_ckpt\n",
    "    else test_args.runs_path / 'checkpoints' / 'best.ckpt'\n",
    ")\n",
    "model = WSIPipeline.load_from_checkpoint(ckpt_path, args=test_args, weights_only=False)\n",
    "test_trainer.test(model, datamodule=dm)\n",
    "\n",
    "print(\"‚úÖ Testing step completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd854b4e",
   "metadata": {},
   "source": [
    "### üìã Load and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf17177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def display_results(results_path):\n",
    "    \"\"\"\n",
    "    Display test results from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        results_path: Path to results.json\n",
    "    \"\"\"\n",
    "    path = Path(results_path)\n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå Results file not found: {path}\")\n",
    "        return\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä TEST RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for key, value in sorted(results.items()):\n",
    "        if 'Test/' in key:\n",
    "            metric_name = key.replace('Test/', '')\n",
    "            print(f\"  {metric_name}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "display_results('/path/to/runs/dataset/model/experiment/results.json')\n",
    "print(\"üìã Results display function ready\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
