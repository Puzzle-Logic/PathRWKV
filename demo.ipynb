{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "27172f75",
      "metadata": {
        "id": "27172f75"
      },
      "source": [
        "<h1 style=\"text-align:center;\">Demo for PathRWKV</h1>\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "![Python](https://img.shields.io/badge/Python-3.12.12-3776AB?style=for-the-badge&logo=python&logoColor=white)\n",
        "![PyTorch](https://img.shields.io/badge/PyTorch-2.9.1-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)\n",
        "![CUDA](https://img.shields.io/badge/CUDA-12.8-76B900?style=for-the-badge&logo=nvidia&logoColor=white)\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "## üìö Summary\n",
        "\n",
        "This notebook demonstrated the complete PathRWKV pipeline:\n",
        "\n",
        "| Step | Description | Output |\n",
        "|------|-------------|--------|\n",
        "| 1Ô∏è‚É£ Preprocessing | WSI ‚Üí Tiles | `.jpeg` images + `dataset.csv` |\n",
        "| 2Ô∏è‚É£ Embedding | Tiles ‚Üí Features | `.safetensors` files |\n",
        "| 3Ô∏è‚É£ Training | Features ‚Üí Model | Checkpoints + TensorBoard logs |\n",
        "| 4Ô∏è‚É£ Testing | Model ‚Üí Metrics | `results.json` |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c02a6d3",
      "metadata": {
        "id": "1c02a6d3"
      },
      "source": [
        "## ‚òÅÔ∏è Google Colab Setup\n",
        "\n",
        "Run this cell only if you are using Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e69b18e0",
      "metadata": {
        "collapsed": true,
        "id": "e69b18e0",
        "outputId": "7b3cbd68-2951-4b71-b02a-22734effa117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Running in Google Colab!\n",
            "Cloning into 'PathRWKV'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 92 (delta 7), reused 86 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 25.25 MiB | 25.18 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/PathRWKV\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.8 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:9 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,328 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,682 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,571 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,288 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,999 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,888 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,605 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Get:24 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:25 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [45.0 kB]\n",
            "Get:26 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:27 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,640 kB]\n",
            "Get:28 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:29 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,293 kB]\n",
            "Fetched 39.3 MB in 4s (9,525 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 110 not upgraded.\n",
            "Need to get 104 kB of archives.\n",
            "After this operation, 297 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenslide0 amd64 3.4.1+dfsg-5build1 [89.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openslide-tools amd64 3.4.1+dfsg-5build1 [13.8 kB]\n",
            "Fetched 104 kB in 0s (238 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2026.1.4)\n",
            "Downloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monai-1.5.2-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, monai, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.15.2 monai-1.5.2 pytorch-lightning-2.6.1 torchmetrics-1.8.2\n",
            "Collecting scikit-survival\n",
            "  Downloading scikit_survival-0.26.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting openslide-python\n",
            "  Downloading openslide_python-1.4.3-cp311-abi3-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting ecos (from scikit-survival)\n",
            "  Downloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (1.5.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.0.2)\n",
            "Requirement already satisfied: osqp>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (1.1.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.8,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from scikit-survival) (1.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from osqp>=1.0.2->scikit-survival) (3.1.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->scikit-survival) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8,>=1.6.1->scikit-survival) (3.6.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Downloading scikit_survival-0.26.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openslide_python-1.4.3-cp311-abi3-manylinux1_x86_64.manylinux_2_5_x86_64.whl (36 kB)\n",
            "Downloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m222.1/222.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openslide-python, ecos, scikit-survival\n",
            "Successfully installed ecos-2.0.14 openslide-python-1.4.3 scikit-survival-0.26.0\n",
            "‚úÖ Colab setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Check if running in Colab\n",
        "import os\n",
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üåê Running in Google Colab!\")\n",
        "\n",
        "    # Clone the repository\n",
        "    !git clone https://github.com/Puzzle-Logic/PathRWKV.git\n",
        "    %cd PathRWKV\n",
        "\n",
        "    # Install system dependencies\n",
        "    !apt-get update && apt-get install -y openslide-tools\n",
        "\n",
        "    # Install Python dependencies\n",
        "    !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n",
        "    !pip install pytorch-lightning torchmetrics timm monai polars pyyaml safetensors\n",
        "    !pip install scikit-survival openslide-python pillow tqdm scipy tensorboard matplotlib\n",
        "    print(\"‚úÖ Colab setup complete!\")\n",
        "else:\n",
        "    print(\"üíª Running locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e48c708b",
      "metadata": {
        "id": "e48c708b"
      },
      "source": [
        "## üì¶ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "017611c2",
      "metadata": {
        "id": "017611c2",
        "outputId": "8a843a3c-263d-4c1b-c5ab-8859cdfda764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üêç Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "üî• PyTorch: 2.9.0+cu126\n",
            "üñ•Ô∏è CUDA Available: True\n",
            "üéÆ GPU: Tesla T4\n",
            "üìÅ Project Root: /content/PathRWKV\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the project root\n",
        "if IN_COLAB:\n",
        "    PROJECT_ROOT = Path('/content/PathRWKV')\n",
        "else:\n",
        "    PROJECT_ROOT = Path('.').resolve()\n",
        "\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Print system info\n",
        "print(f\"üêç Python: {sys.version}\")\n",
        "print(f\"üî• PyTorch: {torch.__version__}\")\n",
        "print(f\"üñ•Ô∏è CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05500df9",
      "metadata": {
        "id": "05500df9"
      },
      "source": [
        "---\n",
        "## üóÇÔ∏è Step 1: WSI Preparation\n",
        "\n",
        "This step downloads a test sample (test_001.tif) from CAMELYON16 dataset on AWS3, and converts it into small tiles for feature embedding.\n",
        "\n",
        "### Key Parameters:\n",
        "- `tile_size`: Size of each tile (default: 224√ó224 pixels)\n",
        "- `target_mpp`: Microns per pixel (default: 0.5 for 20x magnification)\n",
        "- `t_occupancy`: Minimum tissue occupancy threshold (default: 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543bb570",
      "metadata": {
        "id": "543bb570"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Download data\n",
        "wsi_dir = Path(\"CAMELYON16\")\n",
        "wsi_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# ÁõÆÊ†áÊñá‰ª∂\n",
        "target_file = wsi_dir / \"test_001.tif\"\n",
        "\n",
        "if not target_file.exists():\n",
        "    print(f\"‚¨áÔ∏è Downloading {target_file.name} from AWS Open Data (CAMELYON16)...\")\n",
        "    # ‰ΩøÁî® AWS CLI ‰∏ãËΩΩÔºå--no-sign-request Ë°®Á§∫‰∏çÈúÄË¶ÅÁôªÂΩï\n",
        "    !aws s3 cp s3://camelyon16/testing/images/test_001.tif {wsi_dir} --no-sign-request\n",
        "    print(\"‚úÖ Download complete!\")\n",
        "else:\n",
        "    print(f\"‚úÖ {target_file.name} already exists.\")\n",
        "\n",
        "# ================== 2. Configuration ==================\n",
        "# Configuration for preprocessing\n",
        "PREPROCESS_CONFIG = {\n",
        "    'input_dir': str(wsi_dir),         # üìÇ Â∑≤Ëá™Âä®ÊåáÂêë‰∏ãËΩΩÁõÆÂΩï ('input_wsi')\n",
        "    'output_dir': 'output_tiles',      # üìÇ ËÆæÁΩÆ‰∏∫ Colab Êú¨Âú∞ËæìÂá∫ÁõÆÂΩï\n",
        "    'tile_size': 224,\n",
        "    'target_mpp': 0.5,\n",
        "    't_occupancy': 0.1,\n",
        "    'num_workers': 8,\n",
        "    'mode': None,  # Set to 'TCGA' for TCGA datasets\n",
        "}\n",
        "\n",
        "print(\"\\nüìã Preprocessing Configuration:\")\n",
        "for key, value in PREPROCESS_CONFIG.items():\n",
        "    print(f\"  ‚Ä¢ {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3566f8",
      "metadata": {
        "id": "9c3566f8"
      },
      "outputs": [],
      "source": [
        "# Run preprocessing\n",
        "# ‚ö†Ô∏è This may take a long time\n",
        "from UpStream.preprocess import process_all_slides\n",
        "\n",
        "process_all_slides(\n",
        "    input_dir=PREPROCESS_CONFIG['input_dir'],\n",
        "    output_dir=PREPROCESS_CONFIG['output_dir'],\n",
        "    tile_size=PREPROCESS_CONFIG['tile_size'],\n",
        "    target_mpp=PREPROCESS_CONFIG['target_mpp'],\n",
        "    t_occupancy=PREPROCESS_CONFIG['t_occupancy'],\n",
        "    num_workers=PREPROCESS_CONFIG['num_workers'],\n",
        "    mode=PREPROCESS_CONFIG['mode'],\n",
        "    gen_thumbnails=True,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Preprocessing step ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b15a935",
      "metadata": {
        "id": "6b15a935"
      },
      "source": [
        "### üìä Visualize Tiling Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74ef83fc",
      "metadata": {
        "id": "74ef83fc"
      },
      "outputs": [],
      "source": [
        "def visualize_tiles(tiles_dir, slide_name, num_tiles=16):\n",
        "    \"\"\"\n",
        "    Visualize sample tiles from a preprocessed slide.\n",
        "\n",
        "    Args:\n",
        "        tiles_dir: Directory containing tile images\n",
        "        slide_name: Name of the slide folder\n",
        "        num_tiles: Number of tiles to display\n",
        "    \"\"\"\n",
        "    slide_dir = Path(tiles_dir) / slide_name\n",
        "\n",
        "    if not slide_dir.exists():\n",
        "        print(f\"‚ùå Slide directory not found: {slide_dir}\")\n",
        "        return\n",
        "\n",
        "    tile_files = list(slide_dir.glob('*.jpeg'))[:num_tiles]\n",
        "\n",
        "    if len(tile_files) == 0:\n",
        "        print(f\"‚ùå No tiles found in {slide_dir}\")\n",
        "        return\n",
        "\n",
        "    # Calculate grid dimensions\n",
        "    n_cols = 4\n",
        "    n_rows = (len(tile_files) + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3*n_rows))\n",
        "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
        "\n",
        "    for idx, (ax, tile_path) in enumerate(zip(axes, tile_files)):\n",
        "        img = Image.open(tile_path)\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(tile_path.stem[:15] + '...' if len(tile_path.stem) > 15 else tile_path.stem)\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for ax in axes[len(tile_files):]:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Sample Tiles from {slide_name}', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_tiles('/path/to/output/tiles', 'slide_001')\n",
        "print(\"üìä Tile visualization function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7735bae9",
      "metadata": {
        "id": "7735bae9"
      },
      "source": [
        "---\n",
        "## üß† Step 2: Feature Embedding\n",
        "\n",
        "Extract features from tiles using **Prov-GigaPath**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d66a2fd",
      "metadata": {
        "id": "1d66a2fd"
      },
      "outputs": [],
      "source": [
        "# Configuration for embedding\n",
        "EMBED_CONFIG = {\n",
        "    'input_dir': '/path/to/tiles/folder',      # üìÇ Directory containing tile folders\n",
        "    'output_dir': '/path/to/embeddings',       # üìÇ Output directory for .safetensors files\n",
        "    'model_name': 'hf_hub:prov-gigapath/prov-gigapath',  # Foundation model\n",
        "    'batch_size': 512,\n",
        "    'num_workers': 8,\n",
        "    'devices': -1,  # -1 for all available GPUs\n",
        "    'compile_model': True,  # Use torch.compile for speedup\n",
        "}\n",
        "\n",
        "print(\"üß† Embedding Configuration:\")\n",
        "for key, value in EMBED_CONFIG.items():\n",
        "    print(f\"  ‚Ä¢ {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c75c190",
      "metadata": {
        "id": "1c75c190"
      },
      "outputs": [],
      "source": [
        "# Set HuggingFace token for Prov-GigaPath (requires access)\n",
        "os.environ['HF_TOKEN'] = 'your_huggingface_token_here'  # üîë Replace with your token\n",
        "\n",
        "# Run embedding extraction\n",
        "# ‚ö†Ô∏è This may take a long time depending on the number of slides\n",
        "from UpStream.embed import main as embed_main\n",
        "\n",
        "class EmbedArgs:\n",
        "    input_dir = EMBED_CONFIG['input_dir']\n",
        "    output_dir = EMBED_CONFIG['output_dir']\n",
        "    model_name = EMBED_CONFIG['model_name']\n",
        "    batch_size = EMBED_CONFIG['batch_size']\n",
        "    num_workers = EMBED_CONFIG['num_workers']\n",
        "    devices = EMBED_CONFIG['devices']\n",
        "    compile_model = EMBED_CONFIG['compile_model']\n",
        "    pretrained = True\n",
        "\n",
        "embed_main(EmbedArgs())\n",
        "\n",
        "print(\"‚úÖ Embedding step ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cad1856",
      "metadata": {
        "id": "4cad1856"
      },
      "source": [
        "### üìä Inspect Embedding Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf5f7e1",
      "metadata": {
        "id": "8bf5f7e1"
      },
      "outputs": [],
      "source": [
        "from safetensors.torch import safe_open\n",
        "\n",
        "def inspect_embeddings(safetensor_path):\n",
        "    \"\"\"\n",
        "    Inspect a safetensor file containing slide embeddings.\n",
        "\n",
        "    Args:\n",
        "        safetensor_path: Path to .safetensors file\n",
        "    \"\"\"\n",
        "    path = Path(safetensor_path)\n",
        "    if not path.exists():\n",
        "        print(f\"‚ùå File not found: {path}\")\n",
        "        return\n",
        "\n",
        "    with safe_open(path, framework='pt', device='cpu') as f:\n",
        "        features = f.get_tensor('features')\n",
        "        coords = f.get_tensor('coords_yx')\n",
        "\n",
        "    print(f\"üìÅ File: {path.name}\")\n",
        "    print(f\"  ‚Ä¢ Number of tiles: {features.shape[0]}\")\n",
        "    print(f\"  ‚Ä¢ Feature dimension: {features.shape[1]}\")\n",
        "    print(f\"  ‚Ä¢ Coordinates shape: {coords.shape}\")\n",
        "    print(f\"  ‚Ä¢ Feature stats: mean={features.mean():.4f}, std={features.std():.4f}\")\n",
        "\n",
        "    # Visualize coordinate distribution\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axes[0].scatter(coords[:, 1], coords[:, 0], alpha=0.5, s=5)\n",
        "    axes[0].set_xlabel('X coordinate')\n",
        "    axes[0].set_ylabel('Y coordinate')\n",
        "    axes[0].set_title('Tile Positions')\n",
        "    axes[0].invert_yaxis()\n",
        "\n",
        "    axes[1].hist(features.mean(dim=1).numpy(), bins=50, edgecolor='black')\n",
        "    axes[1].set_xlabel('Mean Feature Value')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    axes[1].set_title('Feature Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "inspect_embeddings('/path/to/embeddings/slide_001.safetensors')\n",
        "print(\"üìä Embedding inspection function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540aa261",
      "metadata": {
        "id": "540aa261"
      },
      "source": [
        "---\n",
        "## üöÄ Step 3: Training PathRWKV\n",
        "\n",
        "Train **PathRWKV** for multiple instance learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11ed294",
      "metadata": {
        "id": "d11ed294"
      },
      "outputs": [],
      "source": [
        "# Training Configuration\n",
        "TRAIN_CONFIG = {\n",
        "    # Environment\n",
        "    'seed': 42,\n",
        "    'devices': '0',  # GPU ID(s), e.g., '0', '0%1' for multi-GPU\n",
        "\n",
        "    # Data\n",
        "    'data_path': '/path/to/dataset',  # üìÇ Root path containing embeddings\n",
        "    'dataset_name': 'CAMELYON16',     # Dataset name (must match config folder)\n",
        "    'max_tiles': 2000,                # Maximum tiles per slide during training\n",
        "    'num_workers': 8,\n",
        "\n",
        "    # Training\n",
        "    'batch_size': 4,\n",
        "    'epochs': 100,\n",
        "    'lr': 1e-4,\n",
        "    'lrf': 0.1,\n",
        "    'early_stop_epoch': 10,\n",
        "\n",
        "    # Paths\n",
        "    'runs_path': str(PROJECT_ROOT / 'runs'),\n",
        "}\n",
        "\n",
        "print(\"üöÄ Training Configuration:\")\n",
        "for key, value in TRAIN_CONFIG.items():\n",
        "    print(f\"  ‚Ä¢ {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a44858",
      "metadata": {
        "id": "39a44858"
      },
      "outputs": [],
      "source": [
        "# Prepare training arguments\n",
        "class TrainArgs:\n",
        "    def __init__(self, config):\n",
        "        for key, value in config.items():\n",
        "            setattr(self, key, value)\n",
        "        self.mode = 'train'\n",
        "        self.tasks = None  # Use all tasks from config\n",
        "        self.resume_ckpt = None\n",
        "        self.test_ckpt = None\n",
        "        self.val_interval = 1.0\n",
        "        self.disable_pbar = False\n",
        "\n",
        "args = TrainArgs(TRAIN_CONFIG)\n",
        "\n",
        "print(\"üìã Training arguments prepared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ed420b",
      "metadata": {
        "id": "01ed420b"
      },
      "outputs": [],
      "source": [
        "# Run training (uncomment to execute)\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from DownStream.utils.pipeline import WSIPipeline\n",
        "from DownStream.utils.dataset import data_module\n",
        "from DownStream.utils.utils import initialize_experiment\n",
        "\n",
        "seed_everything(args.seed, workers=True)\n",
        "\n",
        "# Initialize experiment\n",
        "(\n",
        "    args.data_path,\n",
        "    args.input_dim,\n",
        "    args.tasks,\n",
        "    args.runs_path,\n",
        "    args.runs_name,\n",
        "    args.devices,\n",
        ") = initialize_experiment(args)\n",
        "\n",
        "# Setup logger and callbacks\n",
        "tb_logger = TensorBoardLogger(\n",
        "    version='tb',\n",
        "    name=args.runs_name,\n",
        "    default_hp_metric=False,\n",
        "    save_dir=str(args.runs_path.parent),\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=args.runs_path / 'checkpoints',\n",
        "    filename='best',\n",
        "    monitor='Val/Loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        ")\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='Val/Loss',\n",
        "    min_delta=0.00001,\n",
        "    patience=args.early_stop_epoch,\n",
        "    verbose=True,\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    logger=tb_logger,\n",
        "    callbacks=[checkpoint_callback, early_stop_callback],\n",
        "    log_every_n_steps=1,\n",
        "    devices=args.devices,\n",
        "    precision='bf16-mixed',\n",
        "    max_epochs=args.epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_model_summary=True,\n",
        "    val_check_interval=args.val_interval,\n",
        "    strategy='ddp' if len(args.devices) != 1 else 'auto',\n",
        ")\n",
        "\n",
        "# Train!\n",
        "dm = data_module(args)\n",
        "model = WSIPipeline(args)\n",
        "trainer.fit(model, datamodule=dm)\n",
        "\n",
        "print(\"‚úÖ Training step completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3bebd4",
      "metadata": {
        "id": "6c3bebd4"
      },
      "source": [
        "### üìà Monitor Training with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7403441a",
      "metadata": {
        "id": "7403441a"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Specify the logs directory\n",
        "%tensorboard --logdir /path/to/runs\n",
        "\n",
        "print(\"üìà TensorBoard ready (uncomment command to launch)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd1775b",
      "metadata": {
        "id": "3bd1775b"
      },
      "source": [
        "---\n",
        "## üìä Step 4: Testing and Evaluation\n",
        "\n",
        "Evaluate the trained model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49127d8a",
      "metadata": {
        "id": "49127d8a"
      },
      "outputs": [],
      "source": [
        "# Testing Configuration\n",
        "TEST_CONFIG = {\n",
        "    **TRAIN_CONFIG,\n",
        "    'test_ckpt': None,  # Path to checkpoint, None uses best.ckpt from runs_path\n",
        "}\n",
        "\n",
        "print(\"üìä Testing Configuration:\")\n",
        "for key in ['data_path', 'dataset_name', 'test_ckpt']:\n",
        "    print(f\"  ‚Ä¢ {key}: {TEST_CONFIG[key]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37c0c97",
      "metadata": {
        "id": "b37c0c97"
      },
      "outputs": [],
      "source": [
        "# Run testing\n",
        "\n",
        "test_args = TrainArgs(TEST_CONFIG)\n",
        "test_args.mode = 'test'\n",
        "\n",
        "seed_everything(test_args.seed, workers=True)\n",
        "\n",
        "(\n",
        "    test_args.data_path,\n",
        "    test_args.input_dim,\n",
        "    test_args.tasks,\n",
        "    test_args.runs_path,\n",
        "    test_args.runs_name,\n",
        "    test_args.devices,\n",
        ") = initialize_experiment(test_args)\n",
        "\n",
        "# Setup trainer for testing\n",
        "test_trainer = Trainer(\n",
        "    logger=False,\n",
        "    callbacks=None,\n",
        "    devices=test_args.devices,\n",
        "    precision='bf16-mixed',\n",
        ")\n",
        "\n",
        "# Load model and test\n",
        "dm = data_module(test_args)\n",
        "ckpt_path = (\n",
        "    test_args.test_ckpt\n",
        "    if test_args.test_ckpt\n",
        "    else test_args.runs_path / 'checkpoints' / 'best.ckpt'\n",
        ")\n",
        "model = WSIPipeline.load_from_checkpoint(ckpt_path, args=test_args, weights_only=False)\n",
        "test_trainer.test(model, datamodule=dm)\n",
        "\n",
        "print(\"‚úÖ Testing step completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd854b4e",
      "metadata": {
        "id": "dd854b4e"
      },
      "source": [
        "### üìã Load and Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf17177",
      "metadata": {
        "id": "acf17177"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def display_results(results_path):\n",
        "    \"\"\"\n",
        "    Display test results from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        results_path: Path to results.json\n",
        "    \"\"\"\n",
        "    path = Path(results_path)\n",
        "    if not path.exists():\n",
        "        print(f\"‚ùå Results file not found: {path}\")\n",
        "        return\n",
        "\n",
        "    with open(path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä TEST RESULTS\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    for key, value in sorted(results.items()):\n",
        "        if 'Test/' in key:\n",
        "            metric_name = key.replace('Test/', '')\n",
        "            print(f\"  {metric_name}: {value:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "display_results('/path/to/runs/dataset/model/experiment/results.json')\n",
        "print(\"üìã Results display function ready\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}